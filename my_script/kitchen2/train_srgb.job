#!/bin/bash
#SBATCH --partition=gpu_a100
#SBATCH --gpus=1
#SBATCH --gpus-per-node=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=18
#SBATCH --time=01:00:00
#SBATCH --output=SECOND_SplaTAM/SplaTAM/my_outputs/rawslam/kitchen2/srgb/%x-%j_straightfromgit.out

# entire script fails if a single command fails
set -e

module purge
module load 2023
module load Anaconda3/2023.07-2
module load CUDA/12.1.1


source SplaTAM/splatam/bin/activate

python -c "import torch; print('Torch:', torch.__version__, 'CUDA:', torch.version.cuda)"
nvcc --version


echo "Running on partition: $SLURM_JOB_PARTITION"
echo "GPU type: $SLURM_JOB_GPUS"
echo "Node: $SLURMD_NODENAME"
echo "Job ID: $SLURM_JOB_ID"


python SECOND_SplaTAM/SplaTAM/scripts/splatam.py SECOND_SplaTAM/SplaTAM/configs/rawSLAM/kitchen2/config_srgb.py